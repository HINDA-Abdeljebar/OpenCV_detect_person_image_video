{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd9d0c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Filepath looks like a hdf5 file but h5py is not available. filepath=C:\\Users\\USER\\Desktop\\MASTER-QL\\Python\\haarcascade_fullbody.xml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1408\\2239121894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load the TensorFlow model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\USER\\\\Desktop\\\\MASTER-QL\\\\Python\\\\haarcascade_fullbody.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Open the video file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    235\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                             raise ImportError(\n\u001b[1;32m--> 237\u001b[1;33m                                 \u001b[1;34m\"Filepath looks like a hdf5 file but h5py is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m                                 \u001b[1;34m\"not available.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                                 \u001b[1;34mf\" filepath={filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Filepath looks like a hdf5 file but h5py is not available. filepath=C:\\Users\\USER\\Desktop\\MASTER-QL\\Python\\haarcascade_fullbody.xml"
     ]
    }
   ],
   "source": [
    "//////////////////////// eml run n bloc 3  ///////////////////// \n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorFlow model\n",
    "model = tf.keras.models.load_model('C:\\\\Users\\\\USER\\\\Desktop\\\\MASTER-QL\\\\Python\\\\haarcascade_fullbody.xml')\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture('C:\\\\Users\\\\USER\\\\Desktop\\\\MASTER-QL\\\\Python\\\\Walking_video.mp4')\n",
    "\n",
    "# Initialize counters for the number of people detected in each frame\n",
    "people_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "# Loop through each frame of the video\n",
    "while True:\n",
    "  # Read the next frame\n",
    "  success, frame = video.read()\n",
    "  if not success:\n",
    "    break\n",
    "\n",
    "  # Preprocess the frame for the model\n",
    "  frame = cv2.resize(frame, (300, 300))\n",
    "  frame = frame.astype('float32') / 255.0\n",
    "  frame = tf.expand_dims(frame, axis=0)\n",
    "\n",
    "  # Run the model and get the predictions\n",
    "  predictions = model.predict(frame)\n",
    "\n",
    "  # Extract the bounding boxes and classes for the people detected\n",
    "  boxes, classes, scores = tf.image.combined_non_max_suppression(\n",
    "      boxes=predictions[:, :, :4],\n",
    "      scores=predictions[:, :, 4],\n",
    "      max_output_size_per_class=1,\n",
    "      max_total_size=1,\n",
    "      iou_threshold=0.5,\n",
    "      score_threshold=0.5\n",
    "  )\n",
    "\n",
    "  # Increment the counters based on the number of people detected\n",
    "  people_count += len(boxes)\n",
    "  frame_count += 1\n",
    "\n",
    "# Print the total number of people detected over the entire video\n",
    "print(f'Number of people detected: {people_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f007d9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (1219027037.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10588\\1219027037.py\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    _, labels.astype(int), stats, _ = cv2.connectedComponentsWithStats(mask)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture('C:\\\\Users\\\\USER\\\\Desktop\\\\MASTER-QL\\\\Python\\\\Walking_video.mp4')\n",
    "\n",
    "# Read the first frame and create a background model\n",
    "success, background = video.read()\n",
    "if not success:\n",
    "  raise Exception('Failed to read the video file')\n",
    "\n",
    "# Convert the background to grayscale and blur it\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background = cv2.GaussianBlur(background, (21, 21), 0)\n",
    "\n",
    "# Initialize counters for the number of people detected in each frame\n",
    "people_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "# Loop through each frame of the video\n",
    "while True:\n",
    "  # Read the next frame\n",
    "  success, frame = video.read()\n",
    "  if not success:\n",
    "    break\n",
    "\n",
    "  # Convert the frame to grayscale and blur it\n",
    "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "\n",
    "  # Subtract the background from the current frame\n",
    "  foreground = cv2.absdiff(background, frame)\n",
    "\n",
    "  # Threshold the foreground image to create a binary mask\n",
    "  _, mask = cv2.threshold(foreground, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "  # Dilate the mask to make it easier to identify connected components\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "  mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "  # Use connected component analysis to identify and count the blobs in the mask\n",
    "  _, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "  people = 0\n",
    "  for label in range(1, labels):\n",
    "    # Extract the bounding box for the blob\n",
    "    x, y, w, h, area = stats[label]\n",
    "    if area > 500:  # Filter out small blobs\n",
    "      # Use K-Means clustering to separate the blob into two clusters\n",
    "      image = frame[y:y+h, x:x+w]\n",
    "      kmeans = KMeans(n_clusters=2)\n",
    "      kmeans.fit(image.reshape((-1, 1)))\n",
    "      # If the two clusters have significantly different intensities, assume the blob represents a person\n",
    "      if abs(kmeans.cluster_centers_[0] - kmeans.cluster_centers_[1]) > 25:\n",
    "        people += 1\n",
    "\n",
    "  # Increment the counters based on the number of people detected\n",
    "  people_count += people\n",
    "  frame_count += 1\n",
    "\n",
    "# Print the total number of people detected over the entire video\n",
    "print(f'Number of people detected: {people_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Addison Sears-Collins\n",
    "# https://automaticaddison.com\n",
    "# Description: Detect pedestrians in a video using the \n",
    "#   Histogram of Oriented Gradients (HOG) method\n",
    " \n",
    "import cv2 # Import the OpenCV library to enable computer vision\n",
    "import numpy as np # Import the NumPy scientific computing library\n",
    "from imutils.object_detection import non_max_suppression # Handle overlapping\n",
    " \n",
    "# Make sure the video file is in the same directory as your code\n",
    "filename = 'C:\\\\Users\\\\USER\\\\Desktop\\\\MASTER-QL\\\\Python\\\\Video1.mp4'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    " \n",
    "# We want to save the output to a video file\n",
    "output_filename = 'detecting_on_street.mp4'\n",
    "output_frames_per_second = 20.0\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Create a HOGDescriptor object\n",
    "  hog = cv2.HOGDescriptor()\n",
    "     \n",
    "  # Initialize the People Detector\n",
    "  hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "     \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    " \n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,  \n",
    "                           fourcc, \n",
    "                           output_frames_per_second, \n",
    "                           file_size) \n",
    "     \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "         \n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    "         \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "         \n",
    "        # Resize the frame\n",
    "      width = int(frame.shape[1] * scale_ratio)\n",
    "      height = int(frame.shape[0] * scale_ratio)\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "             \n",
    "      # Store the original frame\n",
    "      orig_frame = frame.copy()\n",
    "             \n",
    "      # Detect people\n",
    "      # image: a single frame from the video\n",
    "      # winStride: step size in x and y direction of the sliding window\n",
    "      # padding: no. of pixels in x and y direction for padding of \n",
    "      # sliding window\n",
    "      # scale: Detection window size increase coefficient   \n",
    "      # bounding_boxes: Location of detected people\n",
    "      # weights: Weight scores of detected people\n",
    "      # Tweak these parameters for better results\n",
    "      (bounding_boxes, weights) = hog.detectMultiScale(frame, \n",
    "                                                       winStride=(16, 16),\n",
    "                                                       padding=(4, 4), \n",
    "                                                       scale=1.05)\n",
    " \n",
    "      # Draw bounding boxes on the frame\n",
    "      for (x, y, w, h) in bounding_boxes: \n",
    "            cv2.rectangle(orig_frame, \n",
    "            (x, y),  \n",
    "            (x + w, y + h),  \n",
    "            (0, 0, 255), \n",
    "             2)\n",
    "                         \n",
    "      # Get rid of overlapping bounding boxes\n",
    "      # You can tweak the overlapThresh value for better results\n",
    "      bounding_boxes = np.array([[x, y, x + w, y + h] for (\n",
    "                                x, y, w, h) in bounding_boxes])\n",
    "             \n",
    "      selection = non_max_suppression(bounding_boxes, \n",
    "                                      probs=None, \n",
    "                                      overlapThresh=0.45)\n",
    "         \n",
    "      # draw the final bounding boxes\n",
    "      for (x1, y1, x2, y2) in selection:\n",
    "        cv2.rectangle(frame, \n",
    "                     (x1, y1), \n",
    "                     (x2, y2), \n",
    "                     (0, 255, 0), \n",
    "                      4)\n",
    "         \n",
    "      # Write the frame to the output video file\n",
    "      result.write(frame)\n",
    "             \n",
    "      # Display the frame \n",
    "      cv2.imshow(\"Frame\", frame)    \n",
    " \n",
    "      # Display frame for X milliseconds and check if q key is pressed\n",
    "      # q == quit\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "         \n",
    "    # No more video frames left\n",
    "    else:\n",
    "      break\n",
    "             \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "     \n",
    "  # Release the video recording\n",
    "  result.release()\n",
    "     \n",
    "  # Close all windows\n",
    "  cv2.destroyAllWindows() \n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167a5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
